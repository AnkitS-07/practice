{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65b539e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install PyMuPDF pdfplumber python-docx docx2txt spacy sentence-transformers fuzzywuzzy python-Levenshtein scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba391004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6173bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pdfplumber\n",
    "import docx2txt\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import gdown\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d35d3a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "        if len(text.strip()) == 0:\n",
    "            # fallback to pdfplumber\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                for page in pdf.pages:\n",
    "                    text += page.extract_text() or \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {pdf_path}: {e}\")\n",
    "    return text\n",
    "\n",
    "# Function to extract text from DOCX\n",
    "def extract_text_from_docx(docx_path):\n",
    "    try:\n",
    "        return docx2txt.process(docx_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {docx_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Universal function\n",
    "def extract_text(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    if ext == \".pdf\":\n",
    "        return extract_text_from_pdf(file_path)\n",
    "    elif ext in [\".docx\", \".doc\"]:\n",
    "        return extract_text_from_docx(file_path)\n",
    "    else:\n",
    "        print(f\"Unsupported file type: {ext}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "500fa5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving folder 1rUTW1HWSVDbmNImEeiLSzomUW_sqf1Wr JD\n",
      "Processing file 1tD-WLfuiIaoBfQPvH7-tT8U5yCgO4tw- sample_jd_1.pdf\n",
      "Processing file 1zgLxT7St7NXEyvrmnZSJ9u_xYMi_2eZS sample_jd_2.pdf\n",
      "Retrieving folder 11X0ik6xtxUJG8fu0eMOQ34lz0O91DwMc Resumes\n",
      "Processing file 1plJfs4rF9K2f8Z4CMrxenz-eD4yW6RI7 resume - 1.pdf\n",
      "Processing file 1PDk-PCqBQKuOuQAucez3gGDzwMq_gKMc RESUME - 2.pdf\n",
      "Processing file 18PEE4Fs7Gw0GNO0m3NYMtJaqRcYEpmAz resume - 3.pdf\n",
      "Processing file 11EZhpnpivOTHuDNvlFQJiPabyjbHm4d2 Resume - 4.pdf\n",
      "Processing file 1BG_UBW5QUoyyhNOkSR28mfAAmXwaodan Resume - 5.pdf\n",
      "Processing file 11PjE34vi-ptiE7FBXRY8DDaTOGEjwAB5 Resume - 6.pdf\n",
      "Processing file 1bIBGDEQDtaRfQgK78mUPLlqc0VZs5H6t Resume - 7.pdf\n",
      "Processing file 1_JflZvhbN4ULl8OluKpPhuYnmRXa-LNX Resume - 8.pdf\n",
      "Processing file 1hkRDcTlUxU9ymseh2b0ptJNWcP0j8rft Resume - 9.pdf\n",
      "Processing file 1zr0NttWR7Xyy-jYthT9NhPdCUEB_KpcX Resume - 10.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1tD-WLfuiIaoBfQPvH7-tT8U5yCgO4tw-\n",
      "To: c:\\Users\\ANKIT SARKAR\\Downloads\\LINUX\\Automated Resume Checker\\hackathon_data\\JD\\sample_jd_1.pdf\n",
      "100%|██████████| 56.9k/56.9k [00:00<00:00, 454kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1zgLxT7St7NXEyvrmnZSJ9u_xYMi_2eZS\n",
      "To: c:\\Users\\ANKIT SARKAR\\Downloads\\LINUX\\Automated Resume Checker\\hackathon_data\\JD\\sample_jd_2.pdf\n",
      "100%|██████████| 189k/189k [00:00<00:00, 1.22MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1plJfs4rF9K2f8Z4CMrxenz-eD4yW6RI7\n",
      "To: c:\\Users\\ANKIT SARKAR\\Downloads\\LINUX\\Automated Resume Checker\\hackathon_data\\Resumes\\resume - 1.pdf\n",
      "100%|██████████| 77.1k/77.1k [00:00<00:00, 685kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1PDk-PCqBQKuOuQAucez3gGDzwMq_gKMc\n",
      "To: c:\\Users\\ANKIT SARKAR\\Downloads\\LINUX\\Automated Resume Checker\\hackathon_data\\Resumes\\RESUME - 2.pdf\n",
      "100%|██████████| 186k/186k [00:00<00:00, 942kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=18PEE4Fs7Gw0GNO0m3NYMtJaqRcYEpmAz\n",
      "To: c:\\Users\\ANKIT SARKAR\\Downloads\\LINUX\\Automated Resume Checker\\hackathon_data\\Resumes\\resume - 3.pdf\n",
      "100%|██████████| 108k/108k [00:00<00:00, 586kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=11EZhpnpivOTHuDNvlFQJiPabyjbHm4d2\n",
      "To: c:\\Users\\ANKIT SARKAR\\Downloads\\LINUX\\Automated Resume Checker\\hackathon_data\\Resumes\\Resume - 4.pdf\n",
      "100%|██████████| 60.1k/60.1k [00:00<00:00, 506kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1BG_UBW5QUoyyhNOkSR28mfAAmXwaodan\n",
      "To: c:\\Users\\ANKIT SARKAR\\Downloads\\LINUX\\Automated Resume Checker\\hackathon_data\\Resumes\\Resume - 5.pdf\n",
      "100%|██████████| 130k/130k [00:00<00:00, 966kB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=11PjE34vi-ptiE7FBXRY8DDaTOGEjwAB5\n",
      "To: c:\\Users\\ANKIT SARKAR\\Downloads\\LINUX\\Automated Resume Checker\\hackathon_data\\Resumes\\Resume - 6.pdf\n",
      "100%|██████████| 127k/127k [00:00<00:00, 587kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1bIBGDEQDtaRfQgK78mUPLlqc0VZs5H6t\n",
      "To: c:\\Users\\ANKIT SARKAR\\Downloads\\LINUX\\Automated Resume Checker\\hackathon_data\\Resumes\\Resume - 7.pdf\n",
      "100%|██████████| 107k/107k [00:00<00:00, 707kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1_JflZvhbN4ULl8OluKpPhuYnmRXa-LNX\n",
      "To: c:\\Users\\ANKIT SARKAR\\Downloads\\LINUX\\Automated Resume Checker\\hackathon_data\\Resumes\\Resume - 8.pdf\n",
      "100%|██████████| 111k/111k [00:00<00:00, 855kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1hkRDcTlUxU9ymseh2b0ptJNWcP0j8rft\n",
      "To: c:\\Users\\ANKIT SARKAR\\Downloads\\LINUX\\Automated Resume Checker\\hackathon_data\\Resumes\\Resume - 9.pdf\n",
      "100%|██████████| 188k/188k [00:00<00:00, 1.28MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1zr0NttWR7Xyy-jYthT9NhPdCUEB_KpcX\n",
      "To: c:\\Users\\ANKIT SARKAR\\Downloads\\LINUX\\Automated Resume Checker\\hackathon_data\\Resumes\\Resume - 10.pdf\n",
      "100%|██████████| 102k/102k [00:00<00:00, 962kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded folders/files:\n",
      "hackathon_data -> []\n",
      "hackathon_data\\JD -> ['sample_jd_1.pdf', 'sample_jd_2.pdf']\n",
      "hackathon_data\\Resumes -> ['resume - 1.pdf', 'Resume - 10.pdf', 'RESUME - 2.pdf', 'resume - 3.pdf', 'Resume - 4.pdf']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Download completed\n"
     ]
    }
   ],
   "source": [
    "# Google Drive folder link (your sample data)\n",
    "folder_url = \"https://drive.google.com/drive/folders/1sYQLFcgSVll9-nc3gQTbAajXcTpfBhKg\"\n",
    "\n",
    "# Output folder where data will be saved locally\n",
    "output_folder = \"hackathon_data\"\n",
    "\n",
    "# Download entire folder\n",
    "gdown.download_folder(folder_url, output=output_folder, quiet=False)\n",
    "\n",
    "# Check the downloaded structure\n",
    "print(\"Downloaded folders/files:\")\n",
    "for root, dirs, files in os.walk(output_folder):\n",
    "    print(root, \"->\", files[:5])  # show first 5 files in each folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e849de10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders in hackathon_data: ['JD', 'Resumes']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Folders in hackathon_data:\", os.listdir(\"hackathon_data\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a88dd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Resume Text (first 500 chars) =====\n",
      "Pavan Kalyan \n",
      "pavankalyan462@gmail.com |9876543210 | LinkedIn | GitHub  \n",
      "Objective  \n",
      "Enthusiastic and detail-oriented Data Analyst with hands-on experience in Python, SQL, and data  \n",
      "visualization. Skilled in conducting in-depth data analysis, web scraping, and building interactive  \n",
      "dashboards. Proven ability to generate actionable insights and communicate findings clearly. Eager to  \n",
      "contribute to a data-driven organization with strong analytical and collaboration skills.  \n",
      "Skills  \n",
      "Languages \n",
      "\n",
      "===== JD Text (first 500 chars) =====\n",
      "Axion Ray’s mission is to improve the quality and safety of engineered \n",
      "products - airplanes, electric vehicles, and medical devices, by creating the \n",
      "world’s best proactive management platform, powered by the latest \n",
      "advances in artificial intelligence. We're revolutionizing the way next-gen \n",
      "vehicles are made and are partnering with forward-looking engineering \n",
      "leaders to create and deploy AI models that will accelerate our speed to an \n",
      "electric and supersonic future. Axion leverages bleeding-\n"
     ]
    }
   ],
   "source": [
    "# Use the correct folder names\n",
    "resumes_folder = \"hackathon_data/Resumes\"\n",
    "jds_folder = \"hackathon_data/JD\"\n",
    "\n",
    "# List files\n",
    "resume_files = os.listdir(resumes_folder)\n",
    "jd_files = os.listdir(jds_folder)\n",
    "\n",
    "# Pick first files for testing\n",
    "resume_path = os.path.join(resumes_folder, resume_files[0])\n",
    "jd_path = os.path.join(jds_folder, jd_files[0])\n",
    "\n",
    "# Extract text\n",
    "resume_text = extract_text(resume_path)\n",
    "jd_text = extract_text(jd_path)\n",
    "\n",
    "print(\"===== Resume Text (first 500 chars) =====\")\n",
    "print(resume_text[:500])\n",
    "\n",
    "print(\"\\n===== JD Text (first 500 chars) =====\")\n",
    "print(jd_text[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e92af41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total resumes extracted: 10\n",
      "Total JDs extracted: 2\n",
      "\n",
      "Sample resume text (first 300 chars):\n",
      " Pavan Kalyan \n",
      "pavankalyan462@gmail.com |9876543210 | LinkedIn | GitHub  \n",
      "Objective  \n",
      "Enthusiastic and detail-oriented Data Analyst with hands-on experience in Python, SQL, and data  \n",
      "visualization. Skilled in conducting in-depth data analysis, web scraping, and building interactive  \n",
      "dashboards. Pro\n",
      "\n",
      "Sample JD text (first 300 chars):\n",
      " Axion Ray’s mission is to improve the quality and safety of engineered \n",
      "products - airplanes, electric vehicles, and medical devices, by creating the \n",
      "world’s best proactive management platform, powered by the latest \n",
      "advances in artificial intelligence. We're revolutionizing the way next-gen \n",
      "vehic\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store all resumes and their extracted text\n",
    "resumes_dict = {}\n",
    "for file in os.listdir(resumes_folder):\n",
    "    file_path = os.path.join(resumes_folder, file)\n",
    "    resumes_dict[file] = extract_text(file_path)\n",
    "\n",
    "# Dictionary to store all JDs and their extracted text\n",
    "jds_dict = {}\n",
    "for file in os.listdir(jds_folder):\n",
    "    file_path = os.path.join(jds_folder, file)\n",
    "    jds_dict[file] = extract_text(file_path)\n",
    "\n",
    "# Check if dictionaries are ready\n",
    "print(\"Total resumes extracted:\", len(resumes_dict))\n",
    "print(\"Total JDs extracted:\", len(jds_dict))\n",
    "print(\"\\nSample resume text (first 300 chars):\\n\", list(resumes_dict.values())[0][:300])\n",
    "print(\"\\nSample JD text (first 300 chars):\\n\", list(jds_dict.values())[0][:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2d05ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load a pre-trained sentence transformer model for semantic similarity\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # small and fast for hackathons\n",
    "\n",
    "# Example: encode sample text\n",
    "# embeddings = model.encode([resume_text, jd_text])\n",
    "# similarity = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "# print(\"Semantic similarity:\", similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a500e549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def hard_match_score(resume_text, jd_text, threshold=80):\n",
    "    \"\"\"\n",
    "    Returns a score between 0-100 based on keyword overlap\n",
    "    using fuzzy matching.\n",
    "    \"\"\"\n",
    "    # Split JD text into words (simple approach for now)\n",
    "    jd_keywords = set([word.lower() for word in jd_text.split() if len(word) > 2])\n",
    "    resume_words = set([word.lower() for word in resume_text.split() if len(word) > 2])\n",
    "\n",
    "    matched = 0\n",
    "    for kw in jd_keywords:\n",
    "        for rw in resume_words:\n",
    "            if fuzz.ratio(kw, rw) >= threshold:  # fuzzy match threshold\n",
    "                matched += 1\n",
    "                break\n",
    "\n",
    "    score = (matched / len(jd_keywords)) * 100 if jd_keywords else 0\n",
    "    return min(score, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1fa077fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_match_score(resume_text, jd_text):\n",
    "    \"\"\"\n",
    "    Returns a cosine similarity score (0-100) between resume and JD\n",
    "    using embeddings.\n",
    "    \"\"\"\n",
    "    embeddings = model.encode([resume_text, jd_text])\n",
    "    similarity = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "    # Convert similarity (0-1) to 0-100\n",
    "    return round(similarity * 100, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5980bc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Resume-JD Relevance Scores (Filtered + Flexible) =====\n",
      "            Resume  Job_Description  hard_score  semantic_score  final_score  \\\n",
      "0   resume - 1.pdf  sample_jd_1.pdf   21.500000       38.240002    28.200001   \n",
      "1   resume - 1.pdf  sample_jd_2.pdf   45.454545       27.990000    38.470001   \n",
      "2  Resume - 10.pdf  sample_jd_1.pdf   19.000000       23.990000    21.000000   \n",
      "3  Resume - 10.pdf  sample_jd_2.pdf   45.454545       40.439999    43.450001   \n",
      "4   RESUME - 2.pdf  sample_jd_1.pdf   18.500000       33.369999    24.450001   \n",
      "\n",
      "  verdict  \n",
      "0     Low  \n",
      "1  Medium  \n",
      "2     Low  \n",
      "3  Medium  \n",
      "4     Low  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resume</th>\n",
       "      <th>Job_Description</th>\n",
       "      <th>hard_score</th>\n",
       "      <th>semantic_score</th>\n",
       "      <th>final_score</th>\n",
       "      <th>verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resume - 1.pdf</td>\n",
       "      <td>sample_jd_1.pdf</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>38.240002</td>\n",
       "      <td>28.200001</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resume - 1.pdf</td>\n",
       "      <td>sample_jd_2.pdf</td>\n",
       "      <td>45.454545</td>\n",
       "      <td>27.990000</td>\n",
       "      <td>38.470001</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Resume - 10.pdf</td>\n",
       "      <td>sample_jd_1.pdf</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>23.990000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Resume - 10.pdf</td>\n",
       "      <td>sample_jd_2.pdf</td>\n",
       "      <td>45.454545</td>\n",
       "      <td>40.439999</td>\n",
       "      <td>43.450001</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RESUME - 2.pdf</td>\n",
       "      <td>sample_jd_1.pdf</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>33.369999</td>\n",
       "      <td>24.450001</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RESUME - 2.pdf</td>\n",
       "      <td>sample_jd_2.pdf</td>\n",
       "      <td>45.454545</td>\n",
       "      <td>54.980000</td>\n",
       "      <td>49.259998</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>resume - 3.pdf</td>\n",
       "      <td>sample_jd_1.pdf</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>41.930000</td>\n",
       "      <td>29.670000</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>resume - 3.pdf</td>\n",
       "      <td>sample_jd_2.pdf</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>54.130001</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Resume - 4.pdf</td>\n",
       "      <td>sample_jd_1.pdf</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>26.480000</td>\n",
       "      <td>21.690001</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Resume - 4.pdf</td>\n",
       "      <td>sample_jd_2.pdf</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>42.119999</td>\n",
       "      <td>49.580002</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Resume - 5.pdf</td>\n",
       "      <td>sample_jd_1.pdf</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>36.189999</td>\n",
       "      <td>28.879999</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Resume - 5.pdf</td>\n",
       "      <td>sample_jd_2.pdf</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>64.709999</td>\n",
       "      <td>58.610001</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Resume - 6.pdf</td>\n",
       "      <td>sample_jd_1.pdf</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>48.580002</td>\n",
       "      <td>35.029999</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Resume - 6.pdf</td>\n",
       "      <td>sample_jd_2.pdf</td>\n",
       "      <td>40.909091</td>\n",
       "      <td>52.509998</td>\n",
       "      <td>45.549999</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Resume - 7.pdf</td>\n",
       "      <td>sample_jd_1.pdf</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>36.730000</td>\n",
       "      <td>24.889999</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Resume - 7.pdf</td>\n",
       "      <td>sample_jd_2.pdf</td>\n",
       "      <td>45.454545</td>\n",
       "      <td>41.630001</td>\n",
       "      <td>43.919998</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Resume - 8.pdf</td>\n",
       "      <td>sample_jd_1.pdf</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>37.529999</td>\n",
       "      <td>24.610001</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Resume - 8.pdf</td>\n",
       "      <td>sample_jd_2.pdf</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>53.349998</td>\n",
       "      <td>51.340000</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Resume - 9.pdf</td>\n",
       "      <td>sample_jd_1.pdf</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>43.119999</td>\n",
       "      <td>28.950001</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Resume - 9.pdf</td>\n",
       "      <td>sample_jd_2.pdf</td>\n",
       "      <td>40.909091</td>\n",
       "      <td>52.790001</td>\n",
       "      <td>45.660000</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Resume  Job_Description  hard_score  semantic_score  final_score  \\\n",
       "0    resume - 1.pdf  sample_jd_1.pdf   21.500000       38.240002    28.200001   \n",
       "1    resume - 1.pdf  sample_jd_2.pdf   45.454545       27.990000    38.470001   \n",
       "2   Resume - 10.pdf  sample_jd_1.pdf   19.000000       23.990000    21.000000   \n",
       "3   Resume - 10.pdf  sample_jd_2.pdf   45.454545       40.439999    43.450001   \n",
       "4    RESUME - 2.pdf  sample_jd_1.pdf   18.500000       33.369999    24.450001   \n",
       "5    RESUME - 2.pdf  sample_jd_2.pdf   45.454545       54.980000    49.259998   \n",
       "6    resume - 3.pdf  sample_jd_1.pdf   21.500000       41.930000    29.670000   \n",
       "7    resume - 3.pdf  sample_jd_2.pdf   54.545455       53.500000    54.130001   \n",
       "8    Resume - 4.pdf  sample_jd_1.pdf   18.500000       26.480000    21.690001   \n",
       "9    Resume - 4.pdf  sample_jd_2.pdf   54.545455       42.119999    49.580002   \n",
       "10   Resume - 5.pdf  sample_jd_1.pdf   24.000000       36.189999    28.879999   \n",
       "11   Resume - 5.pdf  sample_jd_2.pdf   54.545455       64.709999    58.610001   \n",
       "12   Resume - 6.pdf  sample_jd_1.pdf   26.000000       48.580002    35.029999   \n",
       "13   Resume - 6.pdf  sample_jd_2.pdf   40.909091       52.509998    45.549999   \n",
       "14   Resume - 7.pdf  sample_jd_1.pdf   17.000000       36.730000    24.889999   \n",
       "15   Resume - 7.pdf  sample_jd_2.pdf   45.454545       41.630001    43.919998   \n",
       "16   Resume - 8.pdf  sample_jd_1.pdf   16.000000       37.529999    24.610001   \n",
       "17   Resume - 8.pdf  sample_jd_2.pdf   50.000000       53.349998    51.340000   \n",
       "18   Resume - 9.pdf  sample_jd_1.pdf   19.500000       43.119999    28.950001   \n",
       "19   Resume - 9.pdf  sample_jd_2.pdf   40.909091       52.790001    45.660000   \n",
       "\n",
       "   verdict  \n",
       "0      Low  \n",
       "1   Medium  \n",
       "2      Low  \n",
       "3   Medium  \n",
       "4      Low  \n",
       "5   Medium  \n",
       "6      Low  \n",
       "7     High  \n",
       "8      Low  \n",
       "9   Medium  \n",
       "10     Low  \n",
       "11    High  \n",
       "12  Medium  \n",
       "13  Medium  \n",
       "14     Low  \n",
       "15  Medium  \n",
       "16     Low  \n",
       "17    High  \n",
       "18     Low  \n",
       "19  Medium  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---------- Helper: extract relevant JD text ----------\n",
    "def extract_relevant_jd_text(jd_text):\n",
    "    \"\"\"\n",
    "    Extracts only relevant sections (skills, requirements, qualifications) from JD.\n",
    "    \"\"\"\n",
    "    lines = jd_text.split(\"\\n\")\n",
    "    relevant = [line for line in lines if any(kw in line.lower() for kw in [\"skill\", \"requirement\", \"qualification\"])]\n",
    "    return \" \".join(relevant) if relevant else jd_text  # fallback: full JD if nothing found\n",
    "\n",
    "# ---------- Flexible scoring function ----------\n",
    "def final_relevance_score(resume_text, jd_text, \n",
    "                          hard_weight=0.6, semantic_weight=0.4,\n",
    "                          high_threshold=60, medium_threshold=35):\n",
    "    \"\"\"\n",
    "    Computes weighted hard + semantic scores with configurable weights and thresholds.\n",
    "    \"\"\"\n",
    "    # Use filtered JD for more meaningful hard match\n",
    "    jd_relevant = extract_relevant_jd_text(jd_text)\n",
    "    \n",
    "    # Calculate hard + semantic scores\n",
    "    hard_score = hard_match_score(resume_text, jd_relevant)\n",
    "    semantic_score = semantic_match_score(resume_text, jd_relevant)\n",
    "    \n",
    "    # Weighted final score\n",
    "    final_score = round(hard_score * hard_weight + semantic_score * semantic_weight, 2)\n",
    "    \n",
    "    # Flexible verdict thresholds\n",
    "    if final_score >= high_threshold:\n",
    "        verdict = \"High\"\n",
    "    elif final_score >= medium_threshold:\n",
    "        verdict = \"Medium\"\n",
    "    else:\n",
    "        verdict = \"Low\"\n",
    "    \n",
    "    return {\n",
    "        \"hard_score\": hard_score,\n",
    "        \"semantic_score\": semantic_score,\n",
    "        \"final_score\": final_score,\n",
    "        \"verdict\": verdict\n",
    "    }\n",
    "\n",
    "# ---------- Run evaluation on all pairs ----------\n",
    "results = []\n",
    "\n",
    "# Configurable weights and thresholds\n",
    "HARD_WEIGHT = 0.6\n",
    "SEMANTIC_WEIGHT = 0.4\n",
    "HIGH_THRESHOLD = 50  # adjust to make \"High\" achievable\n",
    "MEDIUM_THRESHOLD = 35\n",
    "\n",
    "for resume_name, resume_text in resumes_dict.items():\n",
    "    for jd_name, jd_text in jds_dict.items():\n",
    "        scores = final_relevance_score(\n",
    "            resume_text, jd_text,\n",
    "            hard_weight=HARD_WEIGHT,\n",
    "            semantic_weight=SEMANTIC_WEIGHT,\n",
    "            high_threshold=HIGH_THRESHOLD,\n",
    "            medium_threshold=MEDIUM_THRESHOLD\n",
    "        )\n",
    "        scores.update({\"Resume\": resume_name, \"Job_Description\": jd_name})\n",
    "        results.append(scores)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df_results = pd.DataFrame(results)[\n",
    "    [\"Resume\", \"Job_Description\", \"hard_score\", \"semantic_score\", \"final_score\", \"verdict\"]\n",
    "]\n",
    "\n",
    "# Show first few rows\n",
    "print(\"===== Resume-JD Relevance Scores (Filtered + Flexible) =====\")\n",
    "print(df_results.head())\n",
    "\n",
    "# Display full table in Jupyter\n",
    "display(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "394128f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain langchain_community google-generativeai langsmith google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "90d7f9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    " #!pip install langchain_google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a93093ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBQO9IPyqgLJUbmJFngEX1tRz8Njb_9pvI\"\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-pro\",\n",
    "    temperature=0.4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b28ffca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised NotFound: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised NotFound: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised NotFound: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised NotFound: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised NotFound: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n"
     ]
    }
   ],
   "source": [
    "# Define Feedback Prompt\n",
    "feedback_prompt = PromptTemplate(\n",
    "    input_variables=[\"resume_text\", \"jd_text\", \"final_score\", \"verdict\"],\n",
    "    template=\"\"\"\n",
    "You are an expert career advisor. A resume has been matched with a job description.\n",
    "\n",
    "Resume Snippet:\n",
    "{resume_text}\n",
    "\n",
    "Job Description Snippet:\n",
    "{jd_text}\n",
    "\n",
    "The system has calculated a final relevance score of {final_score} and classified the match as: {verdict}.\n",
    "\n",
    "Please provide:\n",
    "1. Constructive feedback on the alignment between the resume and job description.\n",
    "2. Key strengths from the resume that match the job.\n",
    "3. Gaps or weaknesses to improve.\n",
    "4. Actionable advice for the candidate to improve the score.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# ✅ Step 4: Build Chain\n",
    "feedback_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=feedback_prompt\n",
    ")\n",
    "\n",
    "# ✅ Step 5: Run Feedback Example\n",
    "feedback = feedback_chain.invoke({\n",
    "    \"resume_text\": \"Skilled in Python, Machine Learning, and NLP with 2 years of project experience.\",\n",
    "    \"jd_text\": \"Looking for a Data Scientist with expertise in Python, deep learning, and cloud deployment.\",\n",
    "    \"final_score\": 45.66,\n",
    "    \"verdict\": \"Medium\"\n",
    "})\n",
    "\n",
    "print(\"=== Generated Feedback ===\")\n",
    "print(feedback[\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
